{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "Ek1DOUY4EpO3",
        "outputId": "4468273b-bf9b-4175-e47c-e4bd820ea115"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'awsglue'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-22ff9cb7afb8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mawsglue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawsglue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetResolvedOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawsglue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlueContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'awsglue'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import sys\n",
        "from awsglue.transforms import *\n",
        "from awsglue.utils import getResolvedOptions\n",
        "from pyspark.context import SparkContext\n",
        "from awsglue.context import GlueContext\n",
        "from awsglue.job import Job\n",
        "\n",
        "# Initialize Glue Context\n",
        "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
        "sc = SparkContext()\n",
        "glueContext = GlueContext(sc)\n",
        "spark = glueContext.spark_session\n",
        "job = Job(glueContext)\n",
        "job.init(args['JOB_NAME'], args)\n",
        "\n",
        "# Extract data from S3\n",
        "datasource0 = glueContext.create_dynamic_frame.from_options(\n",
        "    \"s3\",\n",
        "    {\"paths\": [\"s3://hexaware-data/raw/\"]},\n",
        "    format=\"json\"\n",
        ")\n",
        "\n",
        "# Transform: Clean and preprocess\n",
        "applymapping1 = ApplyMapping.apply(\n",
        "    frame=datasource0,\n",
        "    mappings=[\n",
        "        (\"student_id\", \"string\", \"student_id\", \"string\"),\n",
        "        (\"assessment_score\", \"double\", \"score\", \"double\"),\n",
        "        (\"timestamp\", \"string\", \"assessment_time\", \"timestamp\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load data into centralized storage\n",
        "datasink2 = glueContext.write_dynamic_frame.from_options(\n",
        "    frame=applymapping1,\n",
        "    connection_type=\"s3\",\n",
        "    connection_options={\"path\": \"s3://hexaware-data/processed/\"},\n",
        "    format=\"parquet\"\n",
        ")\n",
        "\n",
        "job.commit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating Assessment Questions with OpenAI GPT-4 (Python)**"
      ],
      "metadata": {
        "id": "t6AJWyR1FSdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# Configure OpenAI API Key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def generate_assessment_question(topic, difficulty):\n",
        "    prompt = f\"Generate a {difficulty} level question on the topic of {topic} suitable for a programming assessment.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in generating programming assessment questions.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    question = response.choices[0].message['content'].strip()\n",
        "    return question\n",
        "\n",
        "# Example Usage\n",
        "topic = \"Data Structures\"\n",
        "difficulty = \"Intermediate\"\n",
        "question = generate_assessment_question(topic, difficulty)\n",
        "print(\"Generated Question:\", question)\n"
      ],
      "metadata": {
        "id": "aOFRO3YzFbcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AWS Lambda Function for Adaptive Assessment (Python)**"
      ],
      "metadata": {
        "id": "4gcBU6EGFn4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import boto3\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Initialize OpenAI API\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    # Parse input data\n",
        "    body = json.loads(event['body'])\n",
        "    learner_id = body['learner_id']\n",
        "    previous_scores = body.get('previous_scores', [])\n",
        "\n",
        "    # Determine next question difficulty\n",
        "    if previous_scores:\n",
        "        average_score = sum(previous_scores) / len(previous_scores)\n",
        "        if average_score > 80:\n",
        "            difficulty = \"Advanced\"\n",
        "        elif average_score > 50:\n",
        "            difficulty = \"Intermediate\"\n",
        "        else:\n",
        "            difficulty = \"Beginner\"\n",
        "    else:\n",
        "        difficulty = \"Beginner\"\n",
        "\n",
        "    # Generate next question\n",
        "    topic = body.get('topic', \"General Programming\")\n",
        "    question = generate_assessment_question(topic, difficulty)\n",
        "\n",
        "    # Return response\n",
        "    return {\n",
        "        'statusCode': 200,\n",
        "        'body': json.dumps({\n",
        "            'question': question,\n",
        "            'difficulty': difficulty\n",
        "        }),\n",
        "        'headers': {\n",
        "            'Content-Type': 'application/json',\n",
        "        },\n",
        "    }\n",
        "\n",
        "def generate_assessment_question(topic, difficulty):\n",
        "    prompt = f\"Generate a {difficulty} level question on the topic of {topic} suitable for a programming assessment.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in generating programming assessment questions.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    question = response.choices[0].message['content'].strip()\n",
        "    return question\n"
      ],
      "metadata": {
        "id": "LjVKvflYFsLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Real-Time Feedback Generation with Apache Spark (Python)**\n"
      ],
      "metadata": {
        "id": "qZ3zYvBaFzwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"RealTimeFeedback\").getOrCreate()\n",
        "\n",
        "# Configure OpenAI API Key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Define UDF to generate feedback\n",
        "def generate_feedback(answer, correct_answer):\n",
        "    prompt = f\"Provide constructive feedback for the following answer:\\n\\nAnswer: {answer}\\n\\nCorrect Answer: {correct_answer}\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an educational assistant providing feedback.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    feedback = response.choices[0].message['content'].strip()\n",
        "    return feedback\n",
        "\n",
        "feedback_udf = udf(generate_feedback, StringType())\n",
        "\n",
        "# Read streaming data from Kafka\n",
        "df = spark.readStream.format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"kafka-server:9092\") \\\n",
        "    .option(\"subscribe\", \"learner-responses\") \\\n",
        "    .load()\n",
        "\n",
        "# Assume value is a JSON string with 'answer' and 'correct_answer'\n",
        "from pyspark.sql.functions import from_json, col\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"answer\", StringType(), True),\n",
        "    StructField(\"correct_answer\", StringType(), True)\n",
        "])\n",
        "\n",
        "responses = df.select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")).select(\"data.*\")\n",
        "\n",
        "# Generate feedback\n",
        "feedback = responses.withColumn(\"feedback\", feedback_udf(col(\"answer\"), col(\"correct_answer\")))\n",
        "\n",
        "# Write feedback back to Kafka\n",
        "feedback.selectExpr(\"CAST(feedback AS STRING) AS value\") \\\n",
        "    .writeStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"kafka-server:9092\") \\\n",
        "    .option(\"topic\", \"learner-feedback\") \\\n",
        "    .option(\"checkpointLocation\", \"/tmp/spark-checkpoints\") \\\n",
        "    .start() \\\n",
        "    .awaitTermination()\n"
      ],
      "metadata": {
        "id": "fo3ToCFgF2rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = pd.read_csv(\"processed_assessment_data.csv\")\n",
        "\n",
        "# Define privileged and unprivileged groups\n",
        "privileged_groups = [{'gender': 1}]\n",
        "unprivileged_groups = [{'gender': 0}]\n",
        "\n",
        "# Create BinaryLabelDataset\n",
        "dataset = BinaryLabelDataset(\n",
        "    df=data,\n",
        "    label_names=['outcome'],\n",
        "    protected_attribute_names=['gender'],\n",
        "    privileged_groups=privileged_groups,\n",
        "    unprivileged_groups=unprivileged_groups\n",
        ")\n",
        "\n",
        "# Apply Reweighing to mitigate bias\n",
        "reweighing = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                        privileged_groups=privileged_groups)\n",
        "dataset_transf = reweighing.fit_transform(dataset)\n",
        "\n",
        "# Train a classifier (example with logistic regression)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
        "\n",
        "X = dataset_transf.features\n",
        "y = dataset_transf.labels.ravel()\n",
        "\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X)\n",
        "dataset_pred = dataset_transf.copy(deepcopy=True)\n",
        "dataset_pred.labels = y_pred\n",
        "\n",
        "# Compute fairness metrics\n",
        "metric = ClassificationMetric(dataset_transf, dataset_pred,\n",
        "                              unprivileged_groups=unprivileged_groups,\n",
        "                              privileged_groups=privileged_groups)\n",
        "print(\"Disparate Impact:\", metric.disparate_impact())\n",
        "print(\"Equal Opportunity Difference:\", metric.equal_opportunity_difference())\n"
      ],
      "metadata": {
        "id": "OsuSZ9_EF6EG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}